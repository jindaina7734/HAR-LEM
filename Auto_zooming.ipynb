{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAFsWDuIPYHL",
        "outputId": "4ab2ca3a-3f93-4fd1-9e2c-ca7185b2237f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 8)) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 9)) (10.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 15)) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 16)) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 17)) (4.66.5)\n",
            "Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 18)) (8.2.93)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 27)) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 42)) (71.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r /content/yolov5/requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r /content/yolov5/requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r /content/yolov5/requirements.txt (line 12)) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r /content/yolov5/requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.0->-r /content/yolov5/requirements.txt (line 12)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (2024.6.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r /content/yolov5/requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r /content/yolov5/requirements.txt (line 18)) (2.0.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /content/yolov5/requirements.txt (line 27)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /content/yolov5/requirements.txt (line 27)) (2024.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r /content/yolov5/requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!cd yolov5\n",
        "!pip install -r /content/yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Define folder containing videos\n",
        "input_folder = '/content/sample_data/bruh'\n",
        "output_folder = '/content/sample_data/bruhh'\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Define fixed size for output video and padding\n",
        "fixed_width, fixed_height = 480, 800  # Example dimensions, adjust as needed\n",
        "padding = 50\n",
        "smoothing_window = 5  # Number of frames for moving average smoothing\n",
        "\n",
        "# Function to apply moving average smoothing\n",
        "def moving_average(data, window_size):\n",
        "    cumsum = np.cumsum(data, dtype=float)\n",
        "    cumsum[window_size:] = cumsum[window_size:] - cumsum[:-window_size]\n",
        "    return cumsum[window_size - 1:] / window_size\n",
        "\n",
        "# Iterate through each file in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.avi', '.mp4', '.mov')):  # Add other formats if needed\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_filename = f'Output_{filename}'\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "        print(f\"Processing file: {filename}\")\n",
        "\n",
        "        # Load video\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        out = None\n",
        "\n",
        "        frame_count = 0\n",
        "        max_width, max_height = 0, 0  # Variables to track max bounding box size\n",
        "        bboxes_x_min = []\n",
        "        bboxes_y_min = []\n",
        "        bboxes_x_max = []\n",
        "        bboxes_y_max = []\n",
        "\n",
        "        # First pass: Determine the largest bounding box size\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Process each frame using YOLOv5 to detect the person with the highest confidence\n",
        "            results = model(frame)\n",
        "\n",
        "            # Extract bounding boxes and confidence scores\n",
        "            detections = results.xyxy[0].numpy()\n",
        "            highest_confidence_person = None\n",
        "            highest_confidence_score = 0.0\n",
        "            largest_bbox_area = 0.0\n",
        "\n",
        "            # Iterate through detections to find the person with the largest bounding box or highest confidence\n",
        "            for detection in detections:\n",
        "                x_min, y_min, x_max, y_max, confidence, class_id = detection\n",
        "                if class_id == 0:  # class_id 0 typically represents 'person' in COCO dataset\n",
        "                    bbox_width, bbox_height = x_max - x_min, y_max - y_min\n",
        "\n",
        "                    # Choose the person with the largest bounding box or highest confidence\n",
        "                    if bbox_width * bbox_height > largest_bbox_area:\n",
        "                        largest_bbox_area = bbox_width * bbox_height\n",
        "                        highest_confidence_person = (x_min, y_min, x_max, y_max)\n",
        "                        highest_confidence_score = confidence\n",
        "\n",
        "                    # Update max width and height\n",
        "                    if bbox_width > max_width:\n",
        "                        max_width = bbox_width\n",
        "                    if bbox_height > max_height:\n",
        "                        max_height = bbox_height\n",
        "\n",
        "        cap.release()  # Close the video file after the first pass\n",
        "\n",
        "        # Second pass: Apply consistent bounding box size with dynamic tracking\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"Failed to retrieve frame or end of video.\")\n",
        "                break\n",
        "\n",
        "            # Process each frame using YOLOv5 to detect the person with the highest confidence\n",
        "            results = model(frame)\n",
        "\n",
        "            # Extract bounding boxes and confidence scores\n",
        "            detections = results.xyxy[0].numpy()\n",
        "            highest_confidence_person = None\n",
        "            highest_confidence_score = 0.0\n",
        "\n",
        "            # Iterate through detections to find the person with the largest bounding box or highest confidence\n",
        "            for detection in detections:\n",
        "                x_min, y_min, x_max, y_max, confidence, class_id = detection\n",
        "                if class_id == 0:  # class_id 0 typically represents 'person' in COCO dataset\n",
        "                    bbox_width, bbox_height = x_max - x_min, y_max - y_min\n",
        "\n",
        "                    # Choose the person with the largest bounding box or highest confidence\n",
        "                    highest_confidence_person = (x_min, y_min, x_max, y_max)\n",
        "\n",
        "            # If a person is detected, adjust the bounding box size\n",
        "            if highest_confidence_person:\n",
        "                x_min, y_min, x_max, y_max = highest_confidence_person\n",
        "\n",
        "                # Calculate the center of the bounding box\n",
        "                center_x = (x_min + x_max) / 2\n",
        "                center_y = (y_min + y_max) / 2\n",
        "\n",
        "                # Append new bounding box coordinates to lists\n",
        "                bboxes_x_min.append(center_x - max_width / 2 - padding)\n",
        "                bboxes_y_min.append(center_y - max_height / 2 - padding)\n",
        "                bboxes_x_max.append(center_x + max_width / 2 + padding)\n",
        "                bboxes_y_max.append(center_y + max_height / 2 + padding)\n",
        "\n",
        "                # Apply moving average smoothing\n",
        "                if len(bboxes_x_min) > smoothing_window:\n",
        "                    smoothed_x_min = moving_average(bboxes_x_min, smoothing_window)[-1]\n",
        "                    smoothed_y_min = moving_average(bboxes_y_min, smoothing_window)[-1]\n",
        "                    smoothed_x_max = moving_average(bboxes_x_max, smoothing_window)[-1]\n",
        "                    smoothed_y_max = moving_average(bboxes_y_max, smoothing_window)[-1]\n",
        "                else:\n",
        "                    smoothed_x_min = bboxes_x_min[-1]\n",
        "                    smoothed_y_min = bboxes_y_min[-1]\n",
        "                    smoothed_x_max = bboxes_x_max[-1]\n",
        "                    smoothed_y_max = bboxes_y_max[-1]\n",
        "\n",
        "                # Ensure bounding box coordinates are within frame bounds\n",
        "                smoothed_x_min = int(max(0, smoothed_x_min))\n",
        "                smoothed_y_min = int(max(0, smoothed_y_min))\n",
        "                smoothed_x_max = int(min(frame.shape[1], smoothed_x_max))\n",
        "                smoothed_y_max = int(min(frame.shape[0], smoothed_y_max))\n",
        "\n",
        "                # Crop the frame based on the smoothed bounding box\n",
        "                cropped_frame = frame[smoothed_y_min:smoothed_y_max, smoothed_x_min:smoothed_x_max]\n",
        "\n",
        "                # Resize cropped frame to fixed size\n",
        "                cropped_frame_resized = cv2.resize(cropped_frame, (fixed_width, fixed_height))\n",
        "\n",
        "                # Initialize VideoWriter if it hasn't been initialized yet\n",
        "                if out is None:\n",
        "                    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "                    out = cv2.VideoWriter(\n",
        "                        output_path,\n",
        "                        fourcc,\n",
        "                        30,  # frame rate\n",
        "                        (fixed_width, fixed_height)  # fixed frame size\n",
        "                    )\n",
        "                out.write(cropped_frame_resized)\n",
        "\n",
        "                frame_count += 1\n",
        "\n",
        "        print(f\"Total frames processed for {filename}: {frame_count}\")\n",
        "        cap.release()\n",
        "        if out:\n",
        "            out.release()\n",
        "\n",
        "print(\"Processing complete. All videos have been processed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N--l9S5SiDQ",
        "outputId": "54c776a0-f2da-49c7-cc6d-9f695ae2bc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:295: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2024-9-15 Python-3.10.12 torch-2.4.0+cu121 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|██████████| 14.1M/14.1M [00:00<00:00, 160MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: S7_walking_toRight_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S7_walking_toRight_sideView_HD.mp4: 401\n",
            "Processing file: S1_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S1_walking_toLeft_sideView_HD.mp4: 304\n",
            "Processing file: S6_walking_toRight_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S6_walking_toRight_sideView_HD.mp4: 446\n",
            "Processing file: S4_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S4_walking_toLeft_sideView_HD.mp4: 224\n",
            "Processing file: S10_walking_toRight_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S10_walking_toRight_sideView_HD.mp4: 363\n",
            "Processing file: S8_walking_toRight_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S8_walking_toRight_sideView_HD.mp4: 348\n",
            "Processing file: S10_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S10_walking_toLeft_sideView_HD.mp4: 367\n",
            "Processing file: S9_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S9_walking_toLeft_sideView_HD.mp4: 322\n",
            "Processing file: S8_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S8_walking_toLeft_sideView_HD.mp4: 396\n",
            "Processing file: S3_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S3_walking_toLeft_sideView_HD.mp4: 48\n",
            "Processing file: S7_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S7_walking_toLeft_sideView_HD.mp4: 404\n",
            "Processing file: S9_walking_toRight_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S9_walking_toRight_sideView_HD.mp4: 308\n",
            "Processing file: S2_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S2_walking_toLeft_sideView_HD.mp4: 194\n",
            "Processing file: S2_walking_toRight_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S2_walking_toRight_sideView_HD.mp4: 154\n",
            "Processing file: S6_walking_toLeft_sideView_HD.mp4\n",
            "Failed to retrieve frame or end of video.\n",
            "Total frames processed for S6_walking_toLeft_sideView_HD.mp4: 470\n",
            "Processing file: S1_walking_toRight_sideView_HD.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RGjo8hXsctUC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}